{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dynamic Routing btw Capsules.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "jUxAYutU5O4w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7b-J2lx0HuO7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will code **Capsule Networks** in PyTorch. We will mainly be working with MNIST dataset only in this "
      ]
    },
    {
      "metadata": {
        "id": "XMtLvSH0XBGi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "from torchvision import transforms, datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2iS9HrO2qHHo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def one_hot_transform(labels):\n",
        "    one_hot = torch.zeros(labels.size()+tuple([10])).scatter_(-1, labels, 1)\n",
        "    return one_hot \n",
        "  \n",
        "trainset = datasets.MNIST ( root='../data', train = True, download = True, transform = transforms.Compose([ transforms.Pad(2), \n",
        "                                                                                                            transforms.RandomCrop(28),\n",
        "                                                                                                            transforms.ToTensor() ]),\n",
        "                            target_transform = one_hot_transform)\n",
        "\n",
        "testset = datasets.MNIST ( root='../data', train = False, download = True, transform = transforms.Compose([ transforms.ToTensor() ]),\n",
        "                            target_transform = one_hot_transform)\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader( trainset, batch_size = 32, shuffle = True, num_workers = 4)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader( testset, batch_size = 32, shuffle = False, num_workers = 4)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9TP2rZIWj9tt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CapsLayer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_iterations=3, num_capsules=1,  num_route_nodes=-1, primary=False, \n",
        "                  caps_dim=-1, kernel_size=None, stride=None):\n",
        "        \n",
        "        super(CapsLayer, self).__init__()\n",
        "        \n",
        "        self.primary = primary\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        \n",
        "        if primary:\n",
        "            self.caps_dim = caps_dim\n",
        "            self.kernel_size = kernel_size\n",
        "            self.stride = stride\n",
        "            self.caps = nn.Conv2d(in_channels, out_channels, kernel_size = self.kernel_size, stride = self.stride, padding=0)\n",
        "        else:\n",
        "            self.num_capsules = num_capsules\n",
        "            self.num_iterations = num_iterations\n",
        "            self.route_weights = nn.Parameter(torch.randn(num_capsules, num_route_nodes, in_channels, out_channels))\n",
        "        \n",
        "    def squash(self, x, dim):\n",
        "        squared_norm = (x**2).sum(dim = dim, keepdim = True)\n",
        "        return (squared_norm / (1+squared_norm)) * x / (squared_norm**0.5)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        if not self.primary:\n",
        "            U = x[:, None, :, None, :] @ self.route_weights[None, :, :, :, :]\n",
        "            B = torch.zeros(U.size()).to(device) #the first device one\n",
        "            for i in range(self.num_iterations):\n",
        "                C = F.softmax(B, dim=2)\n",
        "                V = (C*U).sum(dim=2, keepdim=True)\n",
        "                V = self.squash(V, dim=-1)\n",
        "                B = B+(U*V).sum(dim=-1, keepdim=True).sum(dim=-2, keepdim=True)\n",
        "            V = V.view(-1, V.size(1), V.size(4))\n",
        "        else:\n",
        "            V = [self.caps(x).view(x.size(0), -1, 1) for _ in range(self.caps_dim)]\n",
        "            V = torch.cat(V, dim=-1)\n",
        "            V = self.squash(V, dim=-1)\n",
        "        return V"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pdqvaG7JnA8p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "class CapsNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CapsNet, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 256, kernel_size = 9, stride = 1, padding = 0)\n",
        "        \n",
        "        self.primary = CapsLayer(in_channels = 256, out_channels = 32, primary = True, kernel_size = 9, stride = 2, caps_dim = 8)\n",
        "        \n",
        "        self.digital = CapsLayer(in_channels = 8, out_channels = 16, num_capsules = 10, num_route_nodes = 32*6*6)\n",
        "        \n",
        "        self.reconst = nn.Sequential( nn.Linear(16*10 ,512),\n",
        "                                      nn.ReLU(inplace = True),\n",
        "                                      nn.Linear(512, 1024),\n",
        "                                      nn.ReLU(inplace = True),\n",
        "                                      nn.Linear(1024, 784),\n",
        "                                      nn.Sigmoid()\n",
        "                                    )\n",
        "    \n",
        "    def reconstruction(self, x, y):\n",
        "        recon_images = self.reconst((x*y[:,:,None]).view(-1, 160)).view(-1, 28, 28)\n",
        "        return recon_images\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        l1=F.relu(self.conv1(x))\n",
        "        l2=self.primary(l1)\n",
        "        l3=self.digital(l2)\n",
        "        \n",
        "        preds=F.softmax((((l3**2).sum(dim=-1))**(0.5)), dim=-1)\n",
        "        \n",
        "        return preds, self.reconstruction(l3, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mNz6N0eekjYv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CapsLoss(nn.Module):\n",
        "    def __init__(self, reconstrn_weight = 0.000):\n",
        "        super(CapsLoss, self).__init__()\n",
        "        self.reconstrn_weight = reconstrn_weight\n",
        "    def forward(self, images, labels, preds, reconst_images):\n",
        "        preds = torch.clamp(preds, min=0.1, max=0.9)\n",
        "        margin_loss = (labels*((0.9-preds)**2) + 0.5*(1-labels)*((preds-0.1)**2)).sum()\n",
        "        reconst_loss = ((images-reconst_images)**2).sum()\n",
        "        return (margin_loss + self.reconstrn_weight * reconst_loss) / images.size(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v41ke8qiFA9s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = CapsLoss()\n",
        "net = CapsNet().to(device) #for GPU\n",
        "optimizer = optim.Adam(net.parameters(), lr = 0.0001)\n",
        "\n",
        "for epoch in range(30):  # fix num-epochs as 30.\n",
        "\n",
        "    # training\n",
        "    net.train()\n",
        "    running_loss = 0.0\n",
        "    count = 0.0\n",
        "    for data in train_loader:\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        inputs = (inputs-127.5)/128\n",
        "        outputs, reconst = net(inputs, labels)\n",
        "        loss = criterion(inputs, labels, outputs, reconst)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # statistics\n",
        "        running_loss +=  ( loss.item() * inputs.size(0)) #multiply by the batch size\n",
        "        count += sum(np.argmax(labels.data.cpu().numpy(), 1) == np.argmax(outputs.data.cpu().numpy(), 1)) #the accuracy\n",
        "        \n",
        "    print ( \"epoch num: %d, Train loss: %.5f, Training Accuracy is: %.5f \" % (epoch + 1, running_loss/len(train_loader), count/len(train_loader)) )\n",
        "    \n",
        "    # testing\n",
        "    net.eval()\n",
        "    running_loss = 0.0\n",
        "    count = 0.0\n",
        "    for data in test_loader:\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        \n",
        "        inputs = (inputs-127.5)/128\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # forward \n",
        "        with torch.no_grad():\n",
        "            outputs, reconst = net(inputs, labels)\n",
        "        loss = criterion(inputs, labels, outputs, reconst)\n",
        "\n",
        "        # statistics\n",
        "        running_loss +=  ( loss.item() * inputs.size(0)) #multiply by the batch size\n",
        "        count += sum(np.argmax(labels.data.cpu().numpy(), 1) == np.argmax(outputs.data.cpu().numpy(), 1)) #the accuracy\n",
        "        \n",
        "    print ( \"epoch num: %d, Test loss: %.5f, Testing Accuracy is: %.5f \" % (epoch + 1, running_loss/len(test_loader), count/len(test_loader)) )"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}